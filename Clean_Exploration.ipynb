{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4def8202-18f8-4636-add2-b2ddf62bcb9c",
   "metadata": {},
   "source": [
    "# Group Project Part 2: Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a30d4c42-1004-40b0-b08b-762ee9da2d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary cache directory at /scratch/ialtamirano/job_39288348/matplotlib-t0tm1emh because the default path (/home/jovyan/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30bfada6-e014-4426-b389-41e87ec19590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import csv\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c268fb-1dde-4239-a822-9c341e484a99",
   "metadata": {},
   "source": [
    "# Evaluating the Data\n",
    "\n",
    "---\n",
    "\n",
    "### Dataset Overview\n",
    "Name: WESAD (Wearable Stress and Affect Detection)\n",
    "\n",
    "Link: https://ubi29.informatik.uni-siegen.de/usi/data_wesad.html\n",
    "\n",
    "Citation: Philip Schmidt, Attila Reiss, Robert Duerichen, Claus Marberger and Kristof Van Laerhoven, \"Introducing WESAD, a multimodal dataset for Wearable Stress and Affect Detection\", ICMI 2018, Boulder, USA, 2018.\n",
    "\n",
    "Devices:\n",
    "- RespiBAN (worn on chest): ECG, EDA, EMG, RESP, TEMP, ACC\n",
    "- Empatica E4 (worn on wrist): BVP, EDA, TEMP, ACC <br>\n",
    "\n",
    "---\n",
    "\n",
    "### Subjects and Observations\n",
    "Subjects: 15 total (S2 to S17, excluding S12)\n",
    "\n",
    "Observation Count:\n",
    "\n",
    "- Each subject has ~2–3 million time points\n",
    "- Total labeled observations across dataset: 60,807,600 <br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b88fd7f-9b61-4a28-8d72-18dabd5c5a83",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../ialtamirano/raw_data/WESAD/S2/S2.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m subject \u001b[38;5;129;01min\u001b[39;00m subject_ids:\n\u001b[1;32m     13\u001b[0m     file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_path, subject, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubject\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     15\u001b[0m         data \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(f, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatin1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m         num_obs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/IPython/core/interactiveshell.py:286\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    284\u001b[0m     )\n\u001b[0;32m--> 286\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../ialtamirano/raw_data/WESAD/S2/S2.pkl'"
     ]
    }
   ],
   "source": [
    "#Total Number of Observations:\n",
    "\n",
    "base_path = \"../ialtamirano/raw_data/WESAD\"\n",
    "\n",
    "# List of subject IDs in WESAD dataset (S12 is missing)\n",
    "subject_ids = [f\"S{i}\" for i in range(2, 18) if i != 12]\n",
    "\n",
    "total_observations = 0\n",
    "subject_lengths = {}\n",
    "\n",
    "# Loop through each subject's .pkl file\n",
    "for subject in subject_ids:\n",
    "    file_path = os.path.join(base_path, subject, f\"{subject}.pkl\")\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        data = pickle.load(f, encoding=\"latin1\")\n",
    "        num_obs = len(data['label'])\n",
    "        subject_lengths[subject] = num_obs\n",
    "        total_observations += num_obs\n",
    "\n",
    "print(\"Number of observations per subject:\")\n",
    "for subject, count in subject_lengths.items():\n",
    "    print(f\"  {subject}: {count}\")\n",
    "\n",
    "print(f\"\\nTotal number of labeled observations in the entire dataset: {total_observations}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09f5ce8-4978-4988-93c3-4f3c8b5c4f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Total Observations per Label:\n",
    "\n",
    "np.unique(data['label'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db596164-f415-4db2-bc9a-1d7f2ab62477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#missing data?\n",
    "\n",
    "missing_counts = {}\n",
    "\n",
    "# Loop through chest sensors\n",
    "for sensor, values in data['signal']['chest'].items():\n",
    "    missing = np.isnan(values).sum()\n",
    "    missing_counts[f\"chest_{sensor}\"] = missing\n",
    "\n",
    "# Loop through wrist sensors\n",
    "for sensor, values in data['signal']['wrist'].items():\n",
    "    missing = np.isnan(values).sum()\n",
    "    missing_counts[f\"wrist_{sensor}\"] = missing\n",
    "\n",
    "# Check labels\n",
    "missing_counts['label'] = np.isnan(data['label']).sum()\n",
    "\n",
    "for sensor, count in missing_counts.items():\n",
    "    print(f\"{sensor}: {count} missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9c1241-91fb-47d2-9726-a698b8446088",
   "metadata": {},
   "source": [
    "### review subject s2 as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2112f8-832f-44f5-a0a7-ccf41471e5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # observations for a single Subject S2:\n",
    "\n",
    "with open(\"../ialtamirano/raw_data/WESAD/S2/S2.pkl\", \"rb\") as f:\n",
    "    data = pickle.load(f, encoding=\"latin1\")\n",
    "\n",
    "total_labels = len(data['label'])\n",
    "\n",
    "# Count number of observations for each sensor\n",
    "print(f\"Total labeled observations: {total_labels}\")\n",
    "\n",
    "print(\"\\nChest Sensors:\")\n",
    "for sensor, values in data['signal']['chest'].items():\n",
    "    print(f\"  {sensor}: {values.shape}\")\n",
    "\n",
    "print(\"\\nWrist Sensors:\")\n",
    "for sensor, values in data['signal']['wrist'].items():\n",
    "    print(f\"  {sensor}: {values.shape}\")\n",
    "\n",
    "#The rest of this file will include examples from subject 2..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef7f7bb-1a6a-4201-b9a7-11e5b61a8c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pkl files keys\n",
    "print(data.keys())  #'signal', 'label', 'subject'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58b2f48-f8b0-4be1-8280-4982b4a2cc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 devices signal \n",
    "data['signal'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d0fc61-0e0e-4bed-b337-55c6a9726905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# signal types for each device:\n",
    "print(data['signal']['chest'].keys())  # modalities like ECG, EMG, etc.\n",
    "print(data['signal']['wrist'].keys())  # modalities like BVP, EDA, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689c270a-906f-4bc9-9d89-a5ca666e3bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # of observations for each label:\n",
    "np.unique(data['label'], return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861ad692-f280-4fc1-885f-57c1aa27ad93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example pkl file:\n",
    "\n",
    "# top 5 rows of chest and wrist data\n",
    "chest_data = data['signal']['chest']\n",
    "wrist_data = data['signal']['wrist']\n",
    "\n",
    "for sensor in chest_data:\n",
    "    print(f\"\\n=== Chest Sensor: {sensor} ===\")\n",
    "    display(pd.DataFrame(chest_data[sensor][:5]))\n",
    "\n",
    "for sensor in wrist_data:\n",
    "    print(f\"\\n=== Wrist Sensor: {sensor} ===\")\n",
    "    display(pd.DataFrame(wrist_data[sensor][:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9b913b-3a6d-4e9c-bb58-067b9d2a2f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels:\n",
    "data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77cc020-754e-4cd8-b66f-789818a481be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label counts for S2:\n",
    "labels, counts = np.unique(data['label'], return_counts=True)\n",
    "\n",
    "label_names = {\n",
    "    0: \"Undefined\",\n",
    "    1: \"Baseline\",\n",
    "    2: \"Stress\",\n",
    "    3: \"Amusement\",\n",
    "    4: \"Meditation\",\n",
    "    5: \"Ignore\",\n",
    "    6: \"Ignore\",\n",
    "    7: \"Ignore\"\n",
    "}\n",
    "\n",
    "for l, c in zip(labels, counts):\n",
    "    label = label_names.get(l, \"Unknown\")\n",
    "    print(f\"Label {l} ({label}): {c} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef5872f-ec19-4a5d-8664-16beda5f539c",
   "metadata": {},
   "source": [
    "# Example Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa95670-e8d3-4d38-a851-c65659e96a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ECG Signal During Each Phase\n",
    "\n",
    "# load ECG \n",
    "ecg = data['signal']['chest']['ECG']\n",
    "labels = data['label']\n",
    "\n",
    "# phase names based on data \n",
    "label_names = {1: 'Baseline', 2: 'Stress', 3: 'Amusement', 4: 'Meditation'}\n",
    "\n",
    "# plot segment for each label\n",
    "plt.figure(figsize=(12, 8))\n",
    "for lbl in [1, 2, 3, 4]:\n",
    "    idx = np.where(labels == lbl)[0]\n",
    "    if len(idx) > 0:\n",
    "        segment = ecg[idx[0]:idx[0]+5000]\n",
    "        plt.plot(segment, label=label_names[lbl])\n",
    "\n",
    "plt.title(\"ECG Signal Samples for Different Phases\")\n",
    "plt.xlabel(\"Time (samples)\")\n",
    "plt.ylabel(\"ECG (voltage)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2a4769-2dc7-4a66-aeba-742f037bacd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA Signal by Label\n",
    "\n",
    "eda = data['signal']['chest']['EDA']\n",
    "labels = data['label']\n",
    "label_names = {1: 'Baseline', 2: 'Stress', 3: 'Amusement', 4: 'Meditation'}\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for lbl in [1, 2, 3, 4]:\n",
    "    idx = np.where(labels == lbl)[0]\n",
    "    if len(idx) > 0:\n",
    "        segment = eda[idx[0]:idx[0]+5000]\n",
    "        plt.plot(segment, label=label_names[lbl])\n",
    "\n",
    "plt.title(\"EDA Signal Samples for Different Phases\")\n",
    "plt.xlabel(\"Time (samples)\")\n",
    "plt.ylabel(\"EDA (µS)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2e4864-7a99-454a-9035-7e7f9a9c44ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot of Mean EDA by Label\n",
    "\n",
    "# Get EDA signal and labels\n",
    "eda = data['signal']['chest']['EDA']\n",
    "labels = data['label']\n",
    "label_names = {1: 'Baseline', 2: 'Stress', 3: 'Amusement', 4: 'Meditation'}\n",
    "\n",
    "#  mean EDA values in short windows 5-sec segments\n",
    "sampling_rate = 700\n",
    "window_size = 5 * sampling_rate\n",
    "\n",
    "eda_means_by_label = {1: [], 2: [], 3: [], 4: []}\n",
    "\n",
    "for lbl in eda_means_by_label.keys():\n",
    "    idx = np.where(labels == lbl)[0]\n",
    "    # Slide through the signal in 5-second chunks\n",
    "    for i in range(0, len(idx) - window_size, window_size):\n",
    "        segment = eda[idx[i]:idx[i + window_size]]\n",
    "        if len(segment) == window_size:\n",
    "            eda_means_by_label[lbl].append(np.mean(segment))\n",
    "\n",
    "\n",
    "data_to_plot = [eda_means_by_label[lbl] for lbl in [1, 2, 3, 4]]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(data_to_plot, labels=[label_names[lbl] for lbl in [1, 2, 3, 4]])\n",
    "plt.title(\"Distribution of 5-sec Mean EDA by Condition\")\n",
    "plt.ylabel(\"Mean EDA (µS)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b58d96c-9559-4e7f-9259-c4f89b2406e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrist BVP for each label\n",
    "\n",
    "from scipy.stats import mode\n",
    "\n",
    "# Downsample labels to matching BVP length\n",
    "factor = int(len(data['label']) / len(data['signal']['wrist']['BVP']))\n",
    "labels_downsampled = data['label'][:factor * len(data['signal']['wrist']['BVP'])].reshape(-1, factor)\n",
    "labels_bvp = mode(labels_downsampled, axis=1).mode.flatten()\n",
    "\n",
    "bvp = data['signal']['wrist']['BVP']\n",
    "label_names = {1: 'Baseline', 2: 'Stress', 3: 'Amusement', 4: 'Meditation'}\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for lbl in [1, 2, 3, 4]:\n",
    "    idx = np.where(labels_bvp == lbl)[0]\n",
    "    if len(idx) > 500:\n",
    "        segment = bvp[idx[0]:idx[0] + 500]\n",
    "        plt.plot(segment, label=label_names[lbl])\n",
    "\n",
    "plt.title(\"Wrist BVP Signal for Each Condition\")\n",
    "plt.xlabel(\"Time (samples)\")\n",
    "plt.ylabel(\"BVP (raw units)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda49a67-0551-4ce0-b803-85492d165ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare chest respiration signal- Stress vs. Meditation\n",
    "resp = data['signal']['chest']['Resp']\n",
    "labels = data['label']\n",
    "label_names = {2: 'Stress', 4: 'Meditation'}\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "for lbl in [2, 4]:\n",
    "    idx = np.where(labels == lbl)[0]\n",
    "    if len(idx) > 2000:\n",
    "        segment = resp[idx[0]:idx[0] + 2000]\n",
    "        plt.plot(segment, label=label_names[lbl])\n",
    "\n",
    "plt.title(\"Chest Respiration Signal: Stress vs. Meditation\")\n",
    "plt.xlabel(\"Time (samples)\")\n",
    "plt.ylabel(\"Resp (a.u.)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eaa3d87-3aa9-4d9d-b138-d74f0d84d016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEMP signal from chest & corresponding labels\n",
    "temp = data['signal']['chest']['Temp']\n",
    "labels = data['label']\n",
    "label_names = {1: 'Baseline', 2: 'Stress', 3: 'Amusement', 4: 'Meditation'}\n",
    "\n",
    "# Avg temp in 10-sec windows\n",
    "sampling_rate = 700\n",
    "window_size = 10 * sampling_rate\n",
    "\n",
    "temp_means_by_label = {1: [], 2: [], 3: [], 4: []}\n",
    "\n",
    "for lbl in temp_means_by_label:\n",
    "    idx = np.where(labels == lbl)[0]\n",
    "    for i in range(0, len(idx) - window_size, window_size):\n",
    "        segment = temp[idx[i]:idx[i + window_size]]\n",
    "        if len(segment) == window_size:\n",
    "            temp_means_by_label[lbl].append(np.mean(segment))\n",
    "\n",
    "data_to_plot = [temp_means_by_label[lbl] for lbl in [1, 2, 3, 4]]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(data_to_plot, labels=[label_names[lbl] for lbl in [1, 2, 3, 4]])\n",
    "plt.title(\"Chest Skin Temperature (10s Windows) by Condition\")\n",
    "plt.ylabel(\"Mean Temperature (°C)\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479444b4-3fdc-437e-a566-feafd2ad4eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import mode\n",
    "\n",
    "# label mapping\n",
    "labels = data['label']\n",
    "label_names = {1: 'Baseline', 2: 'Stress', 3: 'Amusement', 4: 'Meditation'}\n",
    "\n",
    "# downsample labels to match wrist signal length\n",
    "wrist_signals = data['signal']['wrist']\n",
    "wrist_len = len(next(iter(wrist_signals.values())))\n",
    "factor = int(len(labels) / wrist_len)\n",
    "\n",
    "labels_downsampled = labels[:factor * wrist_len].reshape(-1, factor)\n",
    "labels_wrist = mode(labels_downsampled, axis=1).mode.flatten()\n",
    "\n",
    "#  plot fcn\n",
    "def plot_signal_by_label(signal, labels, modality, location, is_multichannel=False, axes=None, window=1000):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for lbl in [1, 2, 3, 4]:\n",
    "        idx = np.where(labels == lbl)[0]\n",
    "        if len(idx) > window:\n",
    "            segment = signal[idx[0]:idx[0] + window]\n",
    "            if is_multichannel:\n",
    "                for i, axis in enumerate(axes):\n",
    "                    plt.plot(segment[:, i], label=f'{label_names[lbl]} - {axis}')\n",
    "            else:\n",
    "                plt.plot(segment, label=label_names[lbl])\n",
    "    plt.title(f\"{location.upper()} - {modality} Signal by Label\")\n",
    "    plt.xlabel(\"Time (samples)\")\n",
    "    plt.ylabel(modality)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# CHEST Signals\n",
    "plot_signal_by_label(data['signal']['chest']['ACC'], labels, \"ACC (g)\", \"chest\", is_multichannel=True, axes=['X', 'Y', 'Z'])\n",
    "plot_signal_by_label(data['signal']['chest']['ECG'], labels, \"ECG (voltage)\", \"chest\")\n",
    "plot_signal_by_label(data['signal']['chest']['EMG'], labels, \"EMG (mV)\", \"chest\")\n",
    "plot_signal_by_label(data['signal']['chest']['EDA'], labels, \"EDA (µS)\", \"chest\")\n",
    "plot_signal_by_label(data['signal']['chest']['Temp'], labels, \"Temperature (°C)\", \"chest\")\n",
    "plot_signal_by_label(data['signal']['chest']['Resp'], labels, \"Respiration (a.u.)\", \"chest\")\n",
    "\n",
    "# WRIST Signals (smaller window bc slower sampling rate)\n",
    "plot_signal_by_label(data['signal']['wrist']['ACC'], labels_wrist, \"ACC (g)\", \"wrist\", is_multichannel=True, axes=['X', 'Y', 'Z'], window=200)\n",
    "plot_signal_by_label(data['signal']['wrist']['BVP'], labels_wrist, \"BVP\", \"wrist\", window=200)\n",
    "plot_signal_by_label(data['signal']['wrist']['EDA'], labels_wrist, \"EDA (µS)\", \"wrist\", window=200)\n",
    "plot_signal_by_label(data['signal']['wrist']['TEMP'], labels_wrist, \"Temperature (°C)\", \"wrist\", window=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b41a11e-f4b1-4465-bc72-bc318bfe7b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = df[df['Label'].isin([1, 2, 3, 4])].sample(5000, random_state=42)\n",
    "\n",
    "sns.pairplot(sample_df, hue='Label', vars=['EDA', 'Resp'], palette='Set2')\n",
    "plt.suptitle(\"Signal Relationships (Sampled)\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06c6c5a-7218-4669-9d7e-7d13e60beaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = df[df['Label'].isin([1, 2, 3, 4])].sample(5000, random_state=42)\n",
    "\n",
    "sns.pairplot(sample_df, hue='Label', vars=['EDA', 'BVP'], palette='Set2')\n",
    "plt.suptitle(\"Signal Relationships (Sampled)\", y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60980879-33c6-4c9e-8210-00cf49455052",
   "metadata": {},
   "source": [
    "## Preprocessing data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974cc32c-3df6-4b13-955e-0d792e5cc299",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arely \n",
    "#Copy this into notebook\n",
    "#Function defined to create summary statistics for the final notebook \n",
    "#The window sizes can be adjusted, but this is a great baseline to work with to match labels to sensor data\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, IntegerType\n",
    "from pyspark.sql import Row\n",
    "from scipy.stats import mode\n",
    "\n",
    "\n",
    "# Function to compute stats with labels for windowed data\n",
    "def compute_stats_with_labels(data, labels, window_size=700):\n",
    "    # Ensure the data and labels are aligned\n",
    "    num_windows = len(data) // window_size\n",
    "    data = data[:num_windows * window_size]\n",
    "    labels = labels[:num_windows * window_size]\n",
    "    \n",
    "    # Reshape data into windows\n",
    "    reshaped_data = data.reshape(num_windows, window_size)\n",
    "    reshaped_labels = labels.reshape(num_windows, window_size)\n",
    "    \n",
    "    # Compute statss\n",
    "    stats = np.column_stack([\n",
    "        reshaped_data.mean(axis=1),  # Mean\n",
    "        reshaped_data.std(axis=1),   # Std\n",
    "        reshaped_data.min(axis=1),   # Min\n",
    "        reshaped_data.max(axis=1)    # Max\n",
    "    ])\n",
    "    \n",
    "    # Get majority label for each window\n",
    "    majority_labels = mode(reshaped_labels, axis=1).mode.flatten()\n",
    "    \n",
    "    return stats, majority_labels\n",
    "\n",
    "# Function to extract EDA features and convert to PySpark DataFrame\n",
    "def extract_eda_features_to_spark_df(subject_id, base_path, window_size=700):\n",
    "    file_path = os.path.join(base_path, subject_id, f\"{subject_id}.pkl\")\n",
    "    \n",
    "    with open(file_path, \"rb\") as f:\n",
    "        data = pickle.load(f, encoding=\"latin1\")\n",
    "\n",
    "    # Extract chest and wrist data\n",
    "    chest = data['signal']['chest']\n",
    "    wrist = data['signal']['wrist']\n",
    "    \n",
    "    # Extract labels\n",
    "    labels = data['label']\n",
    "    \n",
    "    # For chest signals (e.g., ACC)\n",
    "    chest_eda = chest['EDA'].flatten()  # Flatten to 1D\n",
    "    chest_features, chest_labels = compute_stats_with_labels(chest_eda, labels, window_size)\n",
    "    \n",
    "    # For wrist signals (e.g., EDA)\n",
    "    wrist_eda = wrist['EDA'].flatten()  # Flatten to 1D\n",
    "    wrist_features, wrist_labels = compute_stats_with_labels(wrist_eda, labels, window_size)\n",
    "    \n",
    "    # Combine features from both chest and wrist (EDA) signals\n",
    "    chest_rows = [\n",
    "        Row(subject_id=subject_id, mean=float(mean), std=float(std), min_=float(min_), max_=float(max_), label=int(label))\n",
    "        for mean, std, min_, max_, label in zip(chest_features[:, 0], chest_features[:, 1], \n",
    "                                                 chest_features[:, 2], chest_features[:, 3], chest_labels)\n",
    "    ]\n",
    "    \n",
    "    wrist_rows = [\n",
    "        Row(subject_id=subject_id, mean=float(mean), std=float(std), min_=float(min_), max_=float(max_), label=int(label))\n",
    "        for mean, std, min_, max_, label in zip(wrist_features[:, 0], wrist_features[:, 1], \n",
    "                                                 wrist_features[:, 2], wrist_features[:, 3], wrist_labels)\n",
    "    ]\n",
    "    \n",
    "    # Define schema explicitly for PySpark DataFrame\n",
    "    schema = StructType([\n",
    "        StructField(\"subject_id\", StringType(), True),\n",
    "        StructField(\"mean\", FloatType(), True),\n",
    "        StructField(\"std\", FloatType(), True),\n",
    "        StructField(\"min\", FloatType(), True),\n",
    "        StructField(\"max\", FloatType(), True),\n",
    "        StructField(\"label\", IntegerType(), True)\n",
    "    ])\n",
    "    \n",
    "    # Create DataFrame from the rows and schema\n",
    "    chest_df = sc.createDataFrame(chest_rows, schema=schema)\n",
    "    wrist_df = sc.createDataFrame(wrist_rows, schema=schema)\n",
    "    \n",
    "    # Combine chest and wrist DataFrames\n",
    "    final_df = chest_df.union(wrist_df)\n",
    "    \n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e0ff26-cf10-40d4-bf50-4d6ba4535f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arely \n",
    "#All subjects into one dataframe\n",
    "\n",
    "# Initialize an empty DataFrame with the same schema as the first one\n",
    "df_all = None\n",
    "\n",
    "for i in range(2, 17):  # From S2 to S17\n",
    "    if i == 12:\n",
    "        continue  # Skip S12\n",
    "    subject_id = f\"S{i}\"\n",
    "    df = extract_eda_features_to_spark_df(subject_id, base_path)\n",
    "    if df_all is None:\n",
    "        df_all = df\n",
    "    else:\n",
    "        df_all = df_all.unionByName(df)\n",
    "\n",
    "# Show the combined DataFrame\n",
    "df_all.show(truncate=False)\n",
    "\n",
    "# Check the label value counts\n",
    "df_all.groupBy(\"label\").count().show()\n",
    "\n",
    "# Check the length of the combined DataFrame\n",
    "print(f\"Combined DataFrame length: {df_all.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043c2c8b-a8dc-419d-8593-d1708e8ebe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arely \n",
    "#copy this to see breakdown of subjects\n",
    "df_all.groupBy(\"subject_id\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af7f92a-d153-4b53-9fde-8a59e059a84c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
