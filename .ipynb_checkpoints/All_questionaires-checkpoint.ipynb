{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea9e3ca7-69ee-48dc-970c-b10f7ba34368",
   "metadata": {},
   "source": [
    "This notebook generates the all_questionnaires.csv file, which comes from every subjects S'X'quest.csv'.\n",
    "Refer to the read.me "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80ac7f2d-35ef-4a64-9273-688604ea3948",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary cache directory at /scratch/tsanchez/job_39246932/matplotlib-rnn4x2ev because the default path (/home/jovyan/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import SparkSession\n",
    "import os\n",
    "import csv\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68e21978-85d5-4351-8d07-415b261757b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"../ialtamirano/raw_data/WESAD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67587c16-91be-4193-a873-d04de4dac323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: Base\n",
      "2: TSST\n",
      "3: Medi 1\n",
      "4: Fun\n",
      "5: Medi 2\n",
      "Tags Present: {'# DIM', '# PANAS', '# END', '# START', '# SSSQ', '# STAI'}\n"
     ]
    }
   ],
   "source": [
    "# check order of experimental conditions in S2_quest.csv\n",
    "quest_path = '../ialtamirano/raw_data/WESAD/S2/S2_quest.csv'\n",
    "\n",
    "# map questionnaire column numbers to experimental conditions\n",
    "with open(quest_path) as f:\n",
    "    for line in f:\n",
    "        if line.startswith('# ORDER'):\n",
    "            order_tokens = line.strip().split(';') \n",
    "            conditions = order_tokens[1:6] # takes the 5 condition names\n",
    "            for idx, cond in enumerate(conditions, start=1):  # pair each condition with 1-based index\n",
    "                print(f'{idx}: {cond}')\n",
    "            break\n",
    "\n",
    "    # read the rest of the file into a list, keeping only non-blank lines:\n",
    "    raw_lines = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# Ge'# TAGS from raw_lines list\n",
    "tags = set()\n",
    "for line in raw_lines:\n",
    "    if line.startswith('#'):\n",
    "        tag = line.split(';')[0]\n",
    "        tags.add(tag)\n",
    "print(f'Tags Present: {tags}')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73fca123-d6cd-48f0-8fdc-04943f98e5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved all questionnaires to ./all_questionnaires.csv\n"
     ]
    }
   ],
   "source": [
    "# combining all questionnaries and storing in new csv\n",
    "QUESTIONNAIRE_CSV_PATH = './all_questionnaires.csv'\n",
    "\n",
    "# Defining names of each of the items based on pdf data file \n",
    "\n",
    "# PANAS: 24 items\n",
    "PANAS_QUESTIONS = [q.lower() for q in [\n",
    "    'Active', 'Distressed', 'Interested', 'Inspired', \n",
    "    'Annoyed', 'Strong', 'Guilty', 'Scared', 'Hostile', 'Excited', \n",
    "    'Proud', 'Irritable', 'Enthusiastic', 'Ashamed', 'Alert', 'Nervous', \n",
    "    'Determined', 'Attentive', 'Jittery', 'Afraid', 'Stressed', 'Frustrated',\n",
    "    'Happy', 'Sad']]\n",
    "\n",
    "# STAI: 6 items\n",
    "STAI_QUESTIONS = [q.lower() for q in ['I_feel_at_ease', 'I_feel_nervous', 'I_am_jittery', 'I_am_relaxed',\n",
    "              'I_am_worried', 'I_feel_pleasant']]\n",
    "    \n",
    "# SAM: 2 items\n",
    "SAM_QUESTIONS = [q.lower() for q in ['Valence', 'Arousal']]\n",
    "\n",
    "#SSSQ: 6 items\n",
    "SSSQ_QUESTIONS = [q.lower() for q in [\n",
    "    'Committed_to_goals', 'Wanted_to_succeed', 'Motivated', \n",
    "    'Reflected_about_self', 'Worried_about_others', 'Concerned_about_impression']]\n",
    "\n",
    "\n",
    "# map each of 4 target conditions to questionnaire indix\n",
    "condition_index_map = {1:0, 2:1, 3:3, 4:2}\n",
    "condition_name_map = {1:'baseline', 2:'stress', 3:'amusement', 4:'meditation'}\n",
    "\n",
    "# initialize dictionary for each (subject, condition) pair. \n",
    "questionnaire_records = []\n",
    "\n",
    "# process ea. subjects questionnaire CSV (exclude invalid)\n",
    "for subject_id in sorted(os.listdir(base_path)):\n",
    "    if not subject_id.startswith('S') or subject_id in {'S1','S12'}:\n",
    "        continue\n",
    "\n",
    "    #setting questionaire file path, read all non-empty lines \n",
    "    csv_path = os.path.join(base_path, subject_id, f'{subject_id}_quest.csv')\n",
    "    with open(csv_path) as f:\n",
    "        raw_line = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "    # filter each raw line into 1 of the 4 possible lists:\n",
    "    panas_lines = [line for line in raw_line if line.startswith('# PANAS')]\n",
    "    stais_lines = [line for line in raw_line if line.startswith('# STAI')]\n",
    "    sams_lines = [line for line in raw_line if line.startswith('# DIM')]\n",
    "    sssq_lines = [line for line in raw_line if line.startswith('# SSSQ')]\n",
    "\n",
    "    #fcn return tokens of items w/out tag\n",
    "    def split_answer_tokens(line):\n",
    "        return line.split(';')[1:] # return only numeric string-no tag\n",
    "\n",
    "\n",
    "    #one record per condition\n",
    "    for condition_id in range(1,5):\n",
    "        record = {\n",
    "            'subject_id': subject_id,\n",
    "            'condition_id': condition_id,\n",
    "            'condition_name': condition_name_map[condition_id]}\n",
    "            \n",
    "        idx = condition_index_map[condition_id]\n",
    "\n",
    "    #for all 4 questionnaires: lets get line, split off tag, get tokens & convert into int\n",
    "        # PANAS: \n",
    "        answers = split_answer_tokens(panas_lines[idx])\n",
    "        \n",
    "        for j, questions in enumerate(PANAS_QUESTIONS):\n",
    "            tokens = answers[j]\n",
    "            try:\n",
    "                record[f'panas_{questions}'] = int(tokens)\n",
    "            except ValueError:\n",
    "                record[f'panas_{questions}'] = pd.NA\n",
    "\n",
    "        # STAI: \n",
    "        answers = split_answer_tokens(stais_lines[idx])\n",
    "        for j, questions in enumerate(STAI_QUESTIONS):\n",
    "            tokens = answers[j]\n",
    "            try:\n",
    "                record[f'stai_{questions}'] = int(tokens)\n",
    "            except ValueError:\n",
    "                record[f'stai_{questions}'] = pd.NA\n",
    "        \n",
    "        # SAM:\n",
    "        answers = split_answer_tokens(sams_lines[idx])\n",
    "\n",
    "        for j, questions in enumerate(SAM_QUESTIONS):\n",
    "            tokens = answers[j]\n",
    "            try:\n",
    "                record[f'sam_{questions}'] = int(tokens)\n",
    "            except ValueError:\n",
    "                record[f'sam_{questions}'] = pd.NA\n",
    "\n",
    "        # SSSQ: ONLY for stress(condition 2)\n",
    "        if condition_id == 2:\n",
    "            answers = split_answer_tokens(sssq_lines[0])\n",
    "            for j, questions in enumerate(SSSQ_QUESTIONS):\n",
    "                tokens = answers[j]\n",
    "                try:\n",
    "                    record[f'sssq_{questions}'] = int(tokens)\n",
    "                except ValueError:\n",
    "                    record[f'sssq_{questions}'] = pd.NA\n",
    "    # for all other conditions, fill SSSQ fields w/ NA nonapplicable                 \n",
    "        else:                                           \n",
    "            for questions in SSSQ_QUESTIONS:\n",
    "                record[f'sssq_{questions}'] = pd.NA  \n",
    "\n",
    "        questionnaire_records.append(record) # append subject-condition dictionary to list \n",
    "\n",
    "\n",
    "# combine & save all records into a DF\n",
    "df_all = pd.DataFrame(questionnaire_records)\n",
    "df_all.to_csv(QUESTIONNAIRE_CSV_PATH, index=False)\n",
    "\n",
    "print('Saved combined to ', QUESTIONNAIRE_CSV_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
